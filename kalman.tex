\section{Kalman Rang Bedingung}

Im Allgemeinen ist es schwer  die Gram'sche Matrix auszurechnen. Die Resolvente ist meist nicht einfach zu berechnen.

Also suchen wir ein handlicheres Kriterium. Dafür ziehen wir uns zunächst auf den zeitunabhängigen Fall zurück. Seien also $A$ und $B$ unabhängig von $t$. Es ist nicht klar, ob dann die Kontrollierbarkeit auch nicht von der Zeit abhängt. Schließlich gehen Anfangs- und Endpunkt in die Lösung mit ein.

Wir betrachten nun das lineare, zeitunabhänige System $\dot{x}=Ax+Bu$ in $[T_0,T_1]$. Ein leicht zu kontrollierbareres Kriterium ist gegeben durch das folgende

\begin{Satz}[Kalman Rang Bedingung]\label{Kalman Rang Bedingung}
  Das lineare, zeitunabhängige System $\dot{x}(t)=Ax(t)+Bu(t)$ ist in $[T_0,T_1]$ kontrollierbar genau dann wenn
\[
  \rang(A^0 \mid A^1B \mid A^2B \mid \dots  \mid A^{n-1}B)=n
\]
\end{Satz}

\begin{Bemerkung}
  Dieser Satz zeigt, dass die Kontrolle des System nicht vom gewählten Intervall abhängt, also komplett zeitunabhängig ist. Wenn ein System auf $[T_0,T_1]$ kontrollierbar ist, dann auch auf $[\tilde{T_0},\tilde{T_1}]$.
\end{Bemerkung}

\begin{Beweis}[zu \ref{Kalman Rang Bedingung}]
 \begin{enumerate}
  \item["`$\Leftarrow$"']
    Da $A$ zeitunabhängig ist können wir die DGL leicht lösen und erhalten die Resolvente $R(t_1,t_2)=e^{(t_1-t_2)A} \; \forall  (t_1,t_2) \in [T_0,T_1]^2$ oder $R(t_1,t_2)=e^{(t_1-t_2)A} \; \forall \: (t_1,t_2) \in [T_0,T_1]^2$

    Bestimmen der Gramschen Matrix
    \begin{align*}
      \G=&\int\limits_{T_0}^{T_1} R(T_1,\tau \cdot B(\tau) \cdot B(\tau)^T \cdot R(T_1,\tau)^T d\tau \\
	=&\int\limits_{T_0}^{T_1} e^{(t_1-\tau)A} B B^T (e^{(t_1-\tau)A})^T d\tau \\
	=&\int\limits_{T_0}^{T_1} e^{(t_1-\tau)A} B B^T e^{(t_1-\tau)A^T} d\tau
    \end{align*}

		Bewiesen wird die Kontraktion, also wird angenommen: $\dot x(t) = Ax(t)+Bu(t)$ ist nicht kontrollierbar in $[T_0,T_1]$. Dann ist $\G$ nicht invertierbar und hat somit einen nicht trivialen Kern. Es exisitert also $y \in \R^n \setminus \{0\}$ mit $\G y=0$
    Also auch
     \[
	y^T \G y = 0 
     \]
     und somit
    \[ 
      0 = c^T \G y = \int\limits_{T_0}^{T_1} \underbrace{|B^T e^{(T_1-\tau)A^T} y |^2}_{ \geq 0} d\tau.
    \]
      Aus der Stetigkeit folgt dann 
     \[  
      B^T e^{(T_1-\tau)A^T} y = 0
     \]
      bzw.
    \[
     0=y^T e^{(T_1-\tau)A} B =: K(\tau), \; \tau \in [T_0,T_1].
    \]
    Es ist 
    \begin{align*}
      K'(\tau)=y^T e^{(T_1-\tau)A} B \cdot (-A) \\
      K'(T_1)=y^T B (-A).
    \end{align*}
    i-faches Differenzen von $K(\tau)$ nach $\tau$ ergibt
    \begin{align*}
      K^{(i)}(\tau)=y^T e^{(T_1-\tau)A} \cdot B (-1)^i A^i \\
      K^{(i)}(T_1)=(-1)^i y^T A^i B
    \end{align*}
    Da $K \equiv 0$ auf $[T_0,T_1]$ gilt auch 
    \[
      K^{(i)}(T_1)=(-1)^i y^T A^i B = 0 \; \forall i \in \N.
    \]
    Insbesondere gilt:
    \[
     y^T A^i B = 0 \; \forall i \in \{0,\dots,n-1\}
    \]
    Das heißt für die Transponierte 
    \[
    	(A^i B)^T y = 0 \; \forall i \in \{0, \dots, n-1\}
    \]
    und damit auch
    \[
    	 (A^0 B | A^1 B | \dots | A^{n-1} B)^T \cdot y= 
    	 \begin{pmatrix}
    	 			(A^0 B)^T \\
    	 			(A^1 B)^T \\
    	 			\hdots \\
    	 			(A^{n-1} B)^T
    	 \end{pmatrix}
    	 \cdot y=0 \in \R^{n^2}
    \]
    Also hat $(A^0 B | A^1 B | \dots | A^{n-1} B)^T$ keinen trivialen Kern, somit keinen vollen Rang. Da der  Zeilenrang gleich dem Spaltenrang ist, muss auch $(A^0 B | A^1 B | \dots | A^{n-1} B)$ nicht vollen Rang haben. Das ist aber ein Widerspruch zur Kalman Rang Bedingung.
   \item["`$\Rightarrow$"']
    Die Rückrichtung wird wieder per Kontraktion gezeigt, die Beweisidee ist dieselbe wie in der Hinrichtung. 

    Angenommen, die Kalman Rang Bedigung wäre nicht erfüllt. Dann existiert ein $y \in \R^n$ mit $y^T A^i B = 0 \; \forall i \in \{0,\dots,n-1\}$.

    Durch Induktion lässt sich folgende Behauptung beweisen:
    Alle Matrizen $A^m$ lassen sich durch eine Linearkombination $\sum\limits_{i=0}^{n-1} \alpha^i A^i $ darstellen
    \begin{enumerate}
      \item[(IA)]
      Betrachte das charakteristische Polynom $\chi_A$ der Matrix $A$.
      \[
	\chi_A = X^n+\alpha_{n-1}X^n-1+\dots+\alpha_0
      \]
      Nach Cayley Hamilton gilt $\chi_A(A)=0$, also
      \[
      0=A^n+\sum\limits_{i=0}^{n-1} \alpha_i A^i \Leftrightarrow A^n = -\sum\limits_{i=0}^{n-1} \alpha_i A^i  
      \]

      \item[(IV)]
      Es gelte die Behauptung für ein beliebiges aber festes $m \in \N$ und alle $l<m$. 

      \item[(IS)]
      $m \mapsto m+1$ 
      \begin{align*}	
      A^{m+1} &= A^m \cdot A \overset{IV}{=} (\sum\limits_{i=0}^{n-1} \alpha_i A^i) A = \sum\limits_{i=0}^{n-1} \alpha_i A^{i+1} = \sum\limits_{i=1}^{n} \alpha_{i-1} A^i \\
							&= \sum\limits_{i=1}^{n-1} \alpha_{i-1} +\alpha_{n-1} A \overset{IA}{=} \sum\limits_{i=1}^{n-1} \alpha_{i-1} A + \sum\limits_{i=0}^{n-1} \beta_i A^i= \sum\limits_{i=0}^{n-1}\gamma_i A^i
		\end{align*}
		\end{enumerate}
		Es folgt die Behauptung per vollständiger Induktion.		
        
		Damit lässt sich für alle $m \in \N, m>n-1$ folgern:
		\[
			y^T A^m B = y^T (-\sum\limits_{i=0}^{n-1}\alpha_i A^i) B = -\sum\limits_{i=0}^{n-1} \alpha_i \underbrace{(y^T A^i B)}_{=0}=0
		\]
		Sei wieder 
		\[
			K(\tau):=y^{T e(T_1-\tau)A} B \; \tau \in [T_0,T_1].
		\]
		Dann ist 
		\[
			K^{(i)}(T_1)= (-1)^i y^T A^i B = 0
		\]
		$K$ ist analytisch, bildet man nun die Taylorreihe um $T_1$
		\[
			K(\tau) = \sum\limits_{i=0}^\infty \frac{K^{(i)}(T_1)}{i!} (\tau-T_1)^i = 0
		\]
		Es ergibt sich aus $\int_{T_0}^{T_1} |K(\tau)|^2 d\tau = 0$, dass
		\[ 
			\int\limits_{T_0}^{T_1} |B^T e^{(T_1-\tau)A^T} y | ^2 d\tau=0
		\]
		und damit auch
		\[
		y^T \G y = 0
		\]
		Da $\G$ semipositiv definit und symmetrisch ist, ist durch $(x,y) = x^T \G y$ eine symmetrische semipositive Bilinearform gegeben und auf diese die Cauchy-Schwarzsche Ungleichung anwendbar: Sei $z \in \R^n$
		\[
			0 \leq |y^T \G z| \leq \underbrace{\sqrt{y^T \G y}}_{=0} \cdot \sqrt{z^T \G z}=0
		\]
		Damit ist 
		\[
			z^T \G y = 0 \forall z \in \R^n,
		\]
		was bedeutet
		\[
			\G y = 0
		\]
		Da $y \neq 0$ ist $\G$ nicht invertierbar, also das System nicht kontrollierbar.
 \end{enumerate}
\end{Beweis}

Jetzt soll das Ergebnis auf den zeitabhängigen Fall übertragen werden. Dafür wird zunächst induktiv die Folge $\{ B_i\}_{i \in \N} \subset \R^{n \times m} ([T_0,T_1])$ wie folgt definiert.
\[
	B_0(t)=B(t); \qquad B_i(t)=\dot B_{i-1}(t) - A(t) \cdot B_{i-1}(t) \; \forall t \in [T_0,T_1]
\]
Damit erhält man folgenden Satz

\begin{Satz}\label{Kalman Rang Bedingung zeitabhängig}
Sei ein $\overline t \in [T_0,T_1]$ und $\{i_1,\dots i_k\}\subset \N$ für ein $k\in \N$ mit
\[
	\rang(B_{i_1} (\overline t)\mid B_{i_2}(\overline t) \mid \dots \mid B_{i_{k}}(\overline t))=n 
\]
Dann ist das System $\dot x(t) = A(t) x +B(t) u(t)$ kontrollierbar in $[T_0,T_1]$
\end{Satz}

\begin{Bemerkung}
Im Gegensatz zum zeitunabhängigen Fall ist jetzt nur noch eine Folgerung gegeben. Und statt vorher nur eine Kombination "der ersten" $n$ Matrizen $A^0B, \dots A^{n-1}B$ zu prüfen war, gibt es jetzt unendlich viele Kominationen der Matrizen $B_i(t)$ für jedes $t \in [T_0,T_1]$. 

Die Forderung ist jedoch notwendig. Sei z.B.  $T_0=0, T_1=1, \;n=m=1 $ und $ A(t)=0, B(t)=t.$ Dann ist $B_0(t)=t, \;  B_1(t)=\dot B_0(t)-A(t)\cdot B_0(t)= B_0(t)=1$ und $B_i(t)=0 \; \forall i >1$. 
	Würde man jetzt für $\overline t=0$ nur den Rang der aus den $n-1$ zusammengesetzten $B_i(\overline t)$ betrachten, ist dieser $\rang(B_0(\overline t)=0$, allerdings ist $\rang(B_1(\overline t)) =1$.
\end{Bemerkung}

\begin{Beweis}[zu \ref{Kalman Rang Bedingung zeitabhängig}]
Annahme: $\dot x(t) = A(t) x + B(t)u(t)$ ist nicht kontrollierbar. Dann ist auch $\G$ nicht invertierbar und hat damit keinen trivialen Kern. Es exisiert also $y \in \R^n, y \neq 0$ mit $\G y =0$.
Also
\[
	0 = y^T \G y = \int\limits_{T_0}^{T_1} \mid B(\tau)^T \cdot R(T_1,\tau)^T \cdot y \mid^2 d\tau 
\]
Wiederum folgt aus der Stetigkeit
\[
	B(\tau)^T\cdot R(T_1,\tau)^T \cdot y = 0 \; \forall \tau \in [T_0,T_1]
\]
Indem $z:=R(T_1,\overline t)^T y$ definiert wird, kommt das $\overline t $ zum Einsatz. Zu bemerken ist, dass aus (\ref{Resolvente Eigenschaften:3}) folgt, dass $R(T_1,\overline t)$ invertierbar ist und damit dann auch $R(T_1,\overline t)^T$. Da $y \neq 0$, ist auch $z \neq 0$.\\
Definiere jetzt
\[
	K(\tau):=z^T R(T_1,\tau) B(\tau) \overset{\ref{Resolvente Eigenschaften:2}}{=} y^T R(T_1,\overline t) R(\overline t, \tau) B(\tau) = 0 \; \forall \tau \in [T_0,T_1]
\]
Ableiten von $K(\tau)$ mithilfe von (\ref{Resolvente Ableitung:2}), und der Produktregel ergibt
\begin{align*}
	K'(\tau) =& z^T(-R(\overline t, \tau)A(\tau)B(\tau))+z^T R(\overline t, \tau)\dot B(\tau) \\
	=& z^T R(\overline t, \tau)(-A(\tau)B(\tau))+ \dot B(\tau)) \\
	=& z^T R(\overline t, \tau) B_1(\tau)	
\end{align*}

Aus
\begin{align*}
	\frac d {d\tau} z^T R(\overline t, \tau) B_i(\tau) =& z^T (A(\tau) R(\overline t, \tau) B_i(\tau)+R(\overline t, \tau) \dot B_i(\tau))\\
	=& z^T R(\overline t, \tau) (\dot B_i(\tau)-(A(\tau)B_i(\tau)\\
	=& z^T R(\overline t, \tau) B_{i+1}(\tau)
\end{align*}
ergibt sich dann für $(i)$-maliges Differenzieren von $K(\tau)$
\[ 
	K^{(i)}(\tau)= z^T R(\overline t, \tau) B_i(\tau).
\]
Da $K \equiv 0$ ist, muss dann auch $K^{(i)} \equiv 0 \; \forall i \in \N$ sein. Also ist insbesondere
\[
	K^{(i)}(\overline t) = z^T R(\overline t, \overline t) B_i(\overline t)=z^T B_i(\overline t)=0 \; \forall i \in \N
\]
Das wiederum heißt
\[
	(B_{i_1}(\overline t) \mid B_{i_2}(\overline t) \mid \dots \mid B_{i_k}(\overline t))^T \cdot z = 
	\begin{pmatrix}
		(B_{i_1}(\overline t))^T \\
		(B_{i_2}(\overline t))^T \\
		\hdots \\
		(B_{i_k}(\overline t))^T
	\end{pmatrix}
	=0 \in \R^{n\times k\cdot m}
\]

Also hat $(B_{i_1}(\overline t) \mid B_{i_2}(\overline t) \mid \dots \mid B_{i_k}(\overline t))^T$ keinen trivialen Kern und damit keinen vollen Rang. Durch die Beziehung Zeilenrang = Spaltenrang gilt dasselbe für $(B_{i_1}(\overline t) \mid B_{i_2}(\overline t) \mid \dots \mid B_{i_k}(\overline t))$, das ist dann die Verneinung der Bedingung aus Satz(\ref{Kalman Rang Bedingung zeitabhängig}).
\end{Beweis}

Es fällt auf, dass in (\ref{Kalman Rang Bedingung zeitabhängig}) nur noch eine Folgerung gegeben ist. Tatsächlich ist es so, dass die Kalman Rang Bedingung nur hinreichend und nicht notwendig ist.
\begin{Beispiel}
	Sei $n=2, m=1, A(t)=0$\\
	Seien $f,g \in \mathcal(C)^\infty([0,1])$ mit 
	\[
		 g \equiv 0 \text{ auf } [0,\frac12] \qquad f \equiv 0 \text{ auf } [\frac12,1]
	\]
	Weiterhin seien $f(0) \neq 0$ und $g(1) \neq 0$, sowie $f^{(i)}(\frac 12)=0=g^{(i)}(\frac 12) \; \forall i \in \N$
	
	Betrachte das System $\dot x(t) = 
		\begin{pmatrix}
			f(t) \\
			g(t)
		\end{pmatrix} u(t) $ auf $[0,1]$.
	
	Da $A=0$ ist die Resolvente $R(T,\tau)=\begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix}=Id_2.$
	\begin{align*}
		\G=& \int\limits_0^1 R(T_1,\tau) B(\tau) B(\tau)^T R(T_1,\tau)^T d\tau \\
			=& \int\limits_0^1 \begin{pmatrix} f(\tau) \\ g(\tau) \end{pmatrix} \cdot \begin{pmatrix} f(\tau) & g(\tau) \end{pmatrix} d\tau \\
			=& \int\limits_0^1 
			\begin{pmatrix}
				f^2(\tau) & (f\cdot g)(\tau) \\
				(f\cdot g)(\tau) & g^2(\tau)
			\end{pmatrix} d\tau
	\end{align*}
Durch die Konstruktion von $f$ und $g$ ergibt sich	
	\[
	\G	= \begin{pmatrix}
				\int\limits_0^1 f^2(\tau)d\tau & 0 \\
				0 & \int\limits_0^1 f^2(\tau)d\tau
			\end{pmatrix}.
	\]
	Da $f$ und $g$ stetig sind und $f(0) \neq 0$ und $g(1) \neq 0$, sind die Integrale über $f^2$ und $g^2$ größer 0 und damit $\G$ invertierbar.
	Dann ist 
	\[
		B_0(t)=\begin{pmatrix} f(t) \\ g(t) \end{pmatrix}, \; B_1(t)=\dot B_0(t) - 0= \begin{pmatrix} f'(t) \\ g'(t) \end{pmatrix}
	\]
	und die für die $B_i(t)$ gilt 
	\[
		B_i(t)=\begin{pmatrix} f^{(i)}(t) \\ g^{(i)}(t) \end{pmatrix}.
	\]
	Sei $k \in N$ und $\{i_1,\dots, i_k\}\subset \N$ endlich.
	
	Mithilfe der Eigenschaft $g^{(i)}=0$ auf $[0,\frac12]$ gilt dann für alle
	\[
		(B_{i_1}(t) \mid B_{i_2}(t) \mid \dots \mid B_{i_k}(t))
		\subset\{\begin{pmatrix}
						a_1 &  \dots & a_k \\
						0 &  \dots & 0
						\end{pmatrix} : a_1,\dots, a_k \in \R \} \qquad \forall t \in [0,\frac12]
	\]
	Genauso ist wegen $f^{(i)}(t)=0$ auf $[\frac12,1]$ dann
	\[
		(B_{i_1}(t) \mid B_{i_2}(t) \mid \dots \mid B_{i_k}(t))
		\subset\{\begin{pmatrix}
						0 &  \dots & 0 \\
						a_1 &  \dots & a_k
						\end{pmatrix} : a_1,\dots, a_k \in \R \} \qquad \forall t \in [\frac12,1]
	\]
	Das heißt für alle $\overline t \in [0,1]$ ist $\rang(B_{i_1}(t) \mid B_{i_2}(t) \mid \dots \mid B_{i_k}(t)) \leq 1 < 2=n$. Also ist Kalman Rang Bedingung nicht erfüllt, das System ist aber kontrollierbar.	 
\end{Beispiel}

\begin{Lemma}
Die Bedingung in Satz (\ref{Kalman Rang Bedingung zeitabhängig}) ist äquivalent zu folgender:
\[
	\operatorname{span}\{B_i(\overline t)u: \; u \in \R^m, i \in \N\}=\R^n \; \text{ für ein } \overline t\in [T_0,T_1]
\]
\end{Lemma}
\begin{Beweis}
Sei $\operatorname{span}\{B_i(\overline t)u: \; u \in \R^m, i \in \N\}=\R^n \; $ für ein $\overline t\in [T_0,T_1]$ und sei $e_1,\dots,e_n$ die Standardbasis des $\R^n$.

Dann gibt es für jedes $i \in \{1,\dots,n\}$ ein $l_i \in \N$ und $\alpha_{ij}\in \R, i_j \in \N, u_{ij} \in \R^m$ für $1 \leq j \leq l_i$ mit
\[
	e_i=\sum\limits_{j=1}^{l_i} \alpha_{ij} B_{i_j}(\overline t) u_{ij}
\]
und jedes $ w \in \R^n$ gibt es dann $w_i \in \R$, so dass
\[
w = \sum\limits_{i=1}^n w_i e_i = \sum\limits_{i=1}^n w_i \sum\limits_{j=1}^{l_i}\alpha_{ij} B_{i_j}(\overline t) u_{ij}.
\]
Da beide Summen endlich sind, können sie zusammengefasst werden.
\begin{align*}
	w=& \sum\limits_{i,j} w_i \alpha_{ij}B_{i_j}(\overline t) u_{ij}	\\
	 =& \sum\limits_{i,j} B_{i_j}(\overline t) w_i \alpha_{ij} u_{ij}	\\
	 =&(B_{1 1}(\overline t) \mid B_{1 2}(\overline t) \mid \dots \mid B_{1 l_1}(\overline t) \mid B_{2 1}(\overline t) \mid \dots \mid B_{n l_n}(\overline t)) \cdot
	 \begin{pmatrix}
	 	w_1 \alpha_{11} u_{11} \\
	 	w_1 \alpha _{12} u_{12} \\
	 	\hdots \\
	 	w_1 \alpha _{1 l_1} u_{1 l_1} \\
	 	w_2 \alpha _{21} u_{21} \\
	 	\hdots \\
	 	w_n \alpha _{n l_n} u_{n l_n} \\
	 \end{pmatrix}
\end{align*}

Das heißt $w$ ist im Bild von $M(\overline t):=(B_{1 1}(\overline t) \mid B_{1 2}(\overline t) \mid \dots \mid B_{1 l_1}(\overline t) \mid B_{2 1}(\overline t) \mid \dots \mid B_{n l_n}(\overline t))$. Da $w \in \R^n $ beliebig war, muss also das Bild von $M(\overline t)$ den ganzen $\R^n$ aufspannen. Aus der linearen Algebra ist bekannt, dass dafür $\rang(M(\overline t)) \geq n$ gelten muss, da $M(\overline t) \in \R^{n \times \sum\limits_{i=1}^n l_i}$ ist gilt auch die Gleichheit. Die Bedingung aus Satz (\ref{Kalman Rang Bedingung zeitabhängig}) ist also durch dieses $M(\overline t)$ gegeben. Da alle Schritte des Beweises auch umkehrbar sind, folgt die Äquivalenz.
\end{Beweis}
